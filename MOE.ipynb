{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MOE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X7H-pklNe13"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# from datasets import Dataset, load_metric\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from transformers import TrainingArguments, Trainer\n",
        "# from transformers import BertForSequenceClassification, BertTokenizer\n",
        "# import json\n",
        "# from transformers import TrainerCallback, EarlyStoppingCallback\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = pd.read_csv('/content/preds.csv')\n",
        "preds = preds.drop([\"Unnamed: 0\", \"Unnamed: 0.1\", \"Unnamed: 0.1.1\", \"Unnamed: 0.1.1.1\", \"Unnamed: 0.1.1.1.1\", \"Unnamed: 0.1.1.1.1.1\", \"Unnamed: 0.1.1.1.1.1.1\"], axis=1)\n"
      ],
      "metadata": {
        "id": "T4_b2GUkiift"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feats = ['bert-base-uncased-wiki', 'bert-base-uncased-sports', 'bert-base-uncased-scouting']\n",
        "label = '# label'\n",
        "x_train, x_test, y_train, y_test = train_test_split(preds[feats].values,\n",
        "                                                    preds[label].values,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=0)\n",
        "print ('Training Set: %d, Test Set: %d \\n' % (len(x_train), len(x_test)))\n",
        "print(\"Sample of features and labels:\")\n",
        "\n",
        "# Take a look at the first 25 training features and corresponding labels\n",
        "for n in range(0,24):\n",
        "    print(x_train[n], y_train[n])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIjZFiByu2ly",
        "outputId": "513465b5-a59d-4679-f927-1b8ea80ac7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set: 1089, Test Set: 467 \n",
            "\n",
            "Sample of features and labels:\n",
            "[1 1 1] 1.0\n",
            "[0 0 0] 0.0\n",
            "[1 1 1] 1.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[0 1 0] 1.0\n",
            "[1 1 1] 1.0\n",
            "[1 1 1] 1.0\n",
            "[1 1 1] 1.0\n",
            "[0 0 0] 0.0\n",
            "[1 1 1] 1.0\n",
            "[1 1 1] 0.0\n",
            "[0 1 1] 1.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[1 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[1 1 1] 1.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n",
            "[0 0 0] 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataset and loader for the training data and labels\n",
        "train_x = torch.Tensor(x_train).float()\n",
        "train_y = torch.Tensor(y_train).float()\n",
        "train_ds = torch.utils.data.TensorDataset(train_x,train_y)\n",
        "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=50,\n",
        "    shuffle=False, num_workers=1)\n",
        "\n",
        "# Create a dataset and loader for the test data and labels\n",
        "test_x = torch.Tensor(x_test).float()\n",
        "test_y = torch.Tensor(y_test).float()\n",
        "test_ds = torch.utils.data.TensorDataset(test_x,test_y)\n",
        "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=50,\n",
        "    shuffle=False, num_workers=1)\n",
        "print('Ready to load data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBBdK_gLwLbC",
        "outputId": "dfc760b5-a609-443e-e632-974004d37e75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to load data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inputs : 3 predictions (one from each expert)\n",
        "#MLP\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BinaryClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassification, self).__init__()\n",
        "        self.layer_1 = nn.Linear(3, 16) \n",
        "        self.layer_2 = nn.Linear(16, 16)\n",
        "        self.layer_out = nn.Linear(16, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        # self.dropout = nn.Dropout(p=0.1)\n",
        "        # self.batchnorm1 = nn.BatchNorm1d(64)\n",
        "        # self.batchnorm2 = nn.BatchNorm1d(64)\n",
        "    def forward(self, inputs):\n",
        "        x = F.relu(self.layer_1(inputs))\n",
        "        x = F.relu(self.layer_2(x))\n",
        "        # x = self.dropout(x)\n",
        "        x = self.layer_out(x)\n",
        "        x = self.sig(x)\n",
        "        return x\n",
        "        \n",
        "model = BinaryClassification()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuJGJR12NvRO",
        "outputId": "745e07d4-4e3c-4c3f-ff5c-f2a6586cdbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BinaryClassification(\n",
            "  (layer_1): Linear(in_features=3, out_features=16, bias=True)\n",
            "  (layer_2): Linear(in_features=16, out_features=16, bias=True)\n",
            "  (layer_out): Linear(in_features=16, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for batch, tensor in enumerate(data_loader):\n",
        "        data, target = tensor\n",
        "        #feedforward\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data).flatten()\n",
        "        # print(\"target \", target)\n",
        "        loss = loss_criteria(out.float(), target.float())\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # backpropagate\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    #Return average loss\n",
        "    avg_loss = train_loss / (batch+1)\n",
        "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
        "    return avg_loss\n",
        "           \n",
        "            \n",
        "def test(model, data_loader):\n",
        "    # Switch the model to evaluation mode (so we don't backpropagate)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    fl_avg = 0\n",
        "    correct = 0\n",
        "    precision_avg = 0\n",
        "    recall_avg = 0\n",
        "    with torch.no_grad():\n",
        "        batch_count = 0\n",
        "        for batch, tensor in enumerate(data_loader):\n",
        "            batch_count += 1\n",
        "            data, target = tensor\n",
        "            # Get the predictions\n",
        "            out = model(data).flatten()\n",
        "\n",
        "            # calculate the loss\n",
        "            test_loss += loss_criteria(out.float(), target.float()).item()\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            predicted = torch.round(out.data)\n",
        "            correct += torch.sum(target==predicted).item()\n",
        "\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(target, predicted, average='binary')\n",
        "            if batch_count == 1:\n",
        "              fl_avg = f1\n",
        "              precision_avg = precision\n",
        "              recall_avg = recall\n",
        "            else:\n",
        "              fl_avg = (fl_avg+f1)/2.0\n",
        "              precision_avg = (precision+precision_avg)/2.0\n",
        "              recall_avg = (recall_avg+recall)/2.0\n",
        "\n",
        "    # Calculate the average loss and total accuracy for this epoch\n",
        "    avg_loss = test_loss/batch_count\n",
        "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        avg_loss, correct, len(data_loader.dataset),\n",
        "        100. * correct / len(data_loader.dataset)))\n",
        "    print('F1:', fl_avg)\n",
        "    print('Recall:', recall_avg)\n",
        "    print('Precision: ', precision_avg)\n",
        "    \n",
        "    # return average loss for the epoch\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "V4qAzAknxEsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the loss criteria (we'll use CrossEntropyLoss for multi-class classification)\n",
        "loss_criteria = nn.BCELoss()\n",
        "\n",
        "# Use an \"Adam\" optimizer to adjust weights\n",
        "# (see https://pytorch.org/docs/stable/optim.html#algorithms for details of supported algorithms)\n",
        "learning_rate = 0.25\n",
        "\n",
        "# We'll track metrics for each epoch in these arrays\n",
        "epoch_nums = []\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Train over 50 epochs\n",
        "epochs = 50\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # learning_rate = learning_rate+0.02\n",
        "    # print(\"lr: \", learning_rate)\n",
        "    \n",
        "    # print the epoch number\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    \n",
        "    # Feed training data into the model to optimize the weights\n",
        "    train_loss = train(model, train_loader, optimizer)\n",
        "    \n",
        "    # Feed the test data into the model to check its performance\n",
        "    test_loss = test(model, train_loader)\n",
        "    \n",
        "    # Log the metrics for this epoch\n",
        "    epoch_nums.append(epoch)\n",
        "    training_loss.append(train_loss)\n",
        "    validation_loss.append(test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB0a0DS13aw3",
        "outputId": "3d756a7b-7d5f-40db-c8da-20c976f572db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "Training set: Average loss: 0.208544\n",
            "Validation set: Average loss: 0.209489, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 2\n",
            "Training set: Average loss: 0.214832\n",
            "Validation set: Average loss: 0.197144, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 3\n",
            "Training set: Average loss: 0.218359\n",
            "Validation set: Average loss: 0.202609, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 4\n",
            "Training set: Average loss: 0.212975\n",
            "Validation set: Average loss: 0.197249, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 5\n",
            "Training set: Average loss: 0.211258\n",
            "Validation set: Average loss: 0.197275, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 6\n",
            "Training set: Average loss: 0.213296\n",
            "Validation set: Average loss: 0.198259, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 7\n",
            "Training set: Average loss: 0.214497\n",
            "Validation set: Average loss: 0.199385, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 8\n",
            "Training set: Average loss: 0.213736\n",
            "Validation set: Average loss: 0.199120, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 9\n",
            "Training set: Average loss: 0.213230\n",
            "Validation set: Average loss: 0.198435, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 10\n",
            "Training set: Average loss: 0.212984\n",
            "Validation set: Average loss: 0.197307, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 11\n",
            "Training set: Average loss: 0.213244\n",
            "Validation set: Average loss: 0.198998, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 12\n",
            "Training set: Average loss: 0.214129\n",
            "Validation set: Average loss: 0.198649, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 13\n",
            "Training set: Average loss: 0.213898\n",
            "Validation set: Average loss: 0.198601, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 14\n",
            "Training set: Average loss: 0.213908\n",
            "Validation set: Average loss: 0.199196, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 15\n",
            "Training set: Average loss: 0.213531\n",
            "Validation set: Average loss: 0.198297, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 16\n",
            "Training set: Average loss: 0.213532\n",
            "Validation set: Average loss: 0.198519, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 17\n",
            "Training set: Average loss: 0.213827\n",
            "Validation set: Average loss: 0.199084, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 18\n",
            "Training set: Average loss: 0.214414\n",
            "Validation set: Average loss: 0.199230, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 19\n",
            "Training set: Average loss: 0.213267\n",
            "Validation set: Average loss: 0.198007, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 20\n",
            "Training set: Average loss: 0.214285\n",
            "Validation set: Average loss: 0.199158, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 21\n",
            "Training set: Average loss: 0.214194\n",
            "Validation set: Average loss: 0.198858, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 22\n",
            "Training set: Average loss: 0.213533\n",
            "Validation set: Average loss: 0.198481, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 23\n",
            "Training set: Average loss: 0.213460\n",
            "Validation set: Average loss: 0.198813, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 24\n",
            "Training set: Average loss: 0.213773\n",
            "Validation set: Average loss: 0.198724, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 25\n",
            "Training set: Average loss: 0.213206\n",
            "Validation set: Average loss: 0.197294, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 26\n",
            "Training set: Average loss: 0.213160\n",
            "Validation set: Average loss: 0.199019, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 27\n",
            "Training set: Average loss: 0.213919\n",
            "Validation set: Average loss: 0.198525, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 28\n",
            "Training set: Average loss: 0.213685\n",
            "Validation set: Average loss: 0.198595, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 29\n",
            "Training set: Average loss: 0.213783\n",
            "Validation set: Average loss: 0.199024, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 30\n",
            "Training set: Average loss: 0.214380\n",
            "Validation set: Average loss: 0.199195, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 31\n",
            "Training set: Average loss: 0.213341\n",
            "Validation set: Average loss: 0.198037, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 32\n",
            "Training set: Average loss: 0.213070\n",
            "Validation set: Average loss: 0.198567, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 33\n",
            "Training set: Average loss: 0.214516\n",
            "Validation set: Average loss: 0.199351, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 34\n",
            "Training set: Average loss: 0.213549\n",
            "Validation set: Average loss: 0.198152, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 35\n",
            "Training set: Average loss: 0.213740\n",
            "Validation set: Average loss: 0.199373, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 36\n",
            "Training set: Average loss: 0.214067\n",
            "Validation set: Average loss: 0.198628, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 37\n",
            "Training set: Average loss: 0.213555\n",
            "Validation set: Average loss: 0.198496, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 38\n",
            "Training set: Average loss: 0.213685\n",
            "Validation set: Average loss: 0.198946, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 39\n",
            "Training set: Average loss: 0.214400\n",
            "Validation set: Average loss: 0.199212, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 40\n",
            "Training set: Average loss: 0.213382\n",
            "Validation set: Average loss: 0.198059, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 41\n",
            "Training set: Average loss: 0.213804\n",
            "Validation set: Average loss: 0.199396, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 42\n",
            "Training set: Average loss: 0.214117\n",
            "Validation set: Average loss: 0.198666, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 43\n",
            "Training set: Average loss: 0.213549\n",
            "Validation set: Average loss: 0.198486, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 44\n",
            "Training set: Average loss: 0.213657\n",
            "Validation set: Average loss: 0.198928, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 45\n",
            "Training set: Average loss: 0.214399\n",
            "Validation set: Average loss: 0.199206, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 46\n",
            "Training set: Average loss: 0.213373\n",
            "Validation set: Average loss: 0.198055, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 47\n",
            "Training set: Average loss: 0.213060\n",
            "Validation set: Average loss: 0.198558, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 48\n",
            "Training set: Average loss: 0.214492\n",
            "Validation set: Average loss: 0.199326, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 49\n",
            "Training set: Average loss: 0.213539\n",
            "Validation set: Average loss: 0.198142, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n",
            "Epoch: 50\n",
            "Training set: Average loss: 0.213736\n",
            "Validation set: Average loss: 0.199366, Accuracy: 1029/1089 (94%)\n",
            "\n",
            "F1: 0.872522178707761\n",
            "Recall: 0.8973542209629055\n",
            "Precision:  0.8517457711946714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(epoch_nums, training_loss)\n",
        "plt.plot(epoch_nums, validation_loss)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['training', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "GvHV5F3rxisR",
        "outputId": "d9534e6b-3578-4c99-85c1-e4bdc7122d26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch doesn't have a built-in confusion matrix metric, so we'll use SciKit-Learn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "\n",
        "# Set the model to evaluate mode\n",
        "model.eval()\n",
        "matplotlib.rcParams.update({'font.size': 12})\n",
        "\n",
        "# Get predictions for the test data\n",
        "x = torch.Tensor(x_test).float()\n",
        "predicted = torch.round(model(x).data)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "cm = confusion_matrix(y_test, predicted.numpy())\n",
        "plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Reds)\n",
        "\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(2)\n",
        "plt.xticks(tick_marks, [\"success\", \"failure\"], rotation=45)\n",
        "plt.yticks(tick_marks, [\"success\", \"failure\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "L38keGDc1-zo",
        "outputId": "22c5de09-b013-476c-f1c1-5e7dc68cf3b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-1bd55f893edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Set the model to evaluate mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'font.size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param_tensor in model.state_dict():\n",
        "    print(param_tensor, \"\\n\", model.state_dict()[param_tensor].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR9qO4DGDQqn",
        "outputId": "d66377a2-a8c5-4473-80e6-6035b5f2bee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer_1.weight \n",
            " [[-7.6361716e-01 -9.6137363e-01 -1.2890092e+00]\n",
            " [-1.6484374e+00 -1.2446281e+00 -2.8065202e-01]\n",
            " [-3.7659967e-01 -1.7605126e-01 -4.0795925e-01]\n",
            " [-3.5579336e-01  3.8047922e-01  5.2891925e-02]\n",
            " [ 2.4721961e+00 -2.7543845e+00  8.4818310e-01]\n",
            " [-9.3265837e-01 -8.5103296e-02 -5.3403342e-01]\n",
            " [-6.4755523e-01 -8.7892908e-01 -1.1558753e+00]\n",
            " [-2.0547803e-01  1.9645396e-01 -2.6580483e-01]\n",
            " [ 8.8290489e-01  2.7862976e+00  2.4327371e+00]\n",
            " [-3.8864744e-01 -1.9766942e-01  3.0926931e-01]\n",
            " [-1.3255872e-01 -2.3699251e-03 -1.5114504e+00]\n",
            " [-7.0394403e-01 -7.9321200e-01 -1.1416259e+00]\n",
            " [ 1.8806453e+00  4.1271353e-01  2.3110182e+00]\n",
            " [ 2.6527099e-02 -7.9279184e-01  3.1459928e-01]\n",
            " [-9.1387916e-01 -9.9957138e-01 -1.2331336e+00]\n",
            " [-1.1269437e+00 -2.3560557e-01 -3.3136231e-01]]\n",
            "layer_1.bias \n",
            " [-1.521756   -1.3786477  -0.07650073 -0.434699   -0.9755504  -1.1950771\n",
            " -1.2158766  -0.5128177  -1.3196591  -0.33840418 -0.18374    -0.57373255\n",
            " -2.4192538  -1.4184285  -0.13554022 -1.1177669 ]\n",
            "layer_2.weight \n",
            " [[ 1.01773119e+00  4.14744556e-01  1.39350027e-01 -2.46575475e-03\n",
            "  -8.74563634e-01 -1.26477444e+00 -1.39528799e+00 -2.46282578e-01\n",
            "  -8.81445765e-01 -2.78404355e-03 -1.04709864e+00 -1.17621124e+00\n",
            "  -6.80010736e-01 -1.13144732e+00 -1.39785409e+00 -9.82074738e-01]\n",
            " [ 1.28322095e-01 -1.21005952e-01  2.13789642e-02  2.03809261e-01\n",
            "  -2.00481981e-01 -9.15096104e-02  3.43347192e-02  2.13584602e-02\n",
            "  -2.47130752e-01  1.85295880e-01  7.27958679e-02 -4.38063741e-02\n",
            "   1.30749285e-01  1.56876564e-01 -3.84093821e-02 -6.16506338e-02]\n",
            " [-1.32759750e+00 -1.38017642e+00 -9.24534500e-02  1.08824313e-01\n",
            "  -1.21633160e+00 -9.88481700e-01 -1.12862980e+00  3.45094204e-02\n",
            "  -1.34423387e+00  7.52681196e-02 -1.27295172e+00 -1.25531626e+00\n",
            "   1.10620946e-01 -9.89260197e-01 -1.22571599e+00 -1.13859594e+00]\n",
            " [ 1.29300356e-03  4.66106921e-01 -1.81741416e-01 -1.49704069e-01\n",
            "  -5.90977073e-01  1.10057104e+00 -8.14877689e-01 -6.68969750e-02\n",
            "  -1.08010960e+00 -2.17548430e-01 -6.29208267e-01 -4.60574001e-01\n",
            "  -1.35001218e+00 -7.08729506e-01 -5.05708277e-01  1.05564356e+00]\n",
            " [ 1.51247323e-01 -9.60074365e-02 -2.42515475e-01 -1.14413738e-01\n",
            "  -1.22269785e+00 -5.55015206e-02 -1.82341307e-01  2.22233564e-01\n",
            "   2.05985904e-02 -3.40842307e-02 -9.05365646e-01 -1.35624409e+00\n",
            "  -3.07250023e-02 -1.29709578e+00 -1.11299944e+00  1.41232997e-01]\n",
            " [ 1.30365729e+00  1.38964975e+00 -1.57267481e-01 -7.94467330e-02\n",
            "   1.08824706e+00 -2.78367400e-02  1.29864240e+00 -4.31068540e-02\n",
            "   1.24307334e+00 -4.38275039e-02 -6.51444077e-01  7.06341803e-01\n",
            "   6.74063265e-01  1.51773989e+00 -1.59912848e+00 -1.77209079e-01]\n",
            " [-1.27935171e+00 -1.41460359e+00 -1.55824035e-01 -1.67350918e-01\n",
            "  -1.56157732e+00  1.38643801e+00 -9.01109219e-01 -2.13302970e-01\n",
            "  -1.12739992e+00  6.02715611e-02 -7.09771156e-01 -5.05259395e-01\n",
            "  -1.87878668e+00 -7.62716174e-01 -5.89265704e-01  1.07980680e+00]\n",
            " [ 1.05506611e+00  1.41190374e+00  7.63503015e-02 -2.04943836e-01\n",
            "   2.69165158e-01 -1.42655337e+00  7.87192762e-01  1.31160736e-01\n",
            "   2.38341503e-02 -1.66928232e-01 -2.04372454e+00  6.53290391e-01\n",
            "  -4.87870246e-01  8.82013857e-01 -1.64699292e+00 -1.36011839e+00]\n",
            " [-1.20164979e+00 -9.92376506e-01  2.00754404e-01 -1.41752839e-01\n",
            "  -1.17731190e+00  1.24706507e-01 -1.04943883e+00  7.75130987e-02\n",
            "  -1.42547417e+00 -1.16303742e-01 -1.24715340e+00 -1.36184120e+00\n",
            "  -1.38863313e+00 -1.37868929e+00 -1.36647666e+00  5.05395234e-02]\n",
            " [ 1.09753788e+00  1.24622822e+00  1.01256937e-01 -1.23264909e-01\n",
            "   4.58771706e-01 -1.42973399e+00 -1.34037101e+00 -9.65604186e-03\n",
            "   8.32749754e-02  1.37550533e-02 -1.18971896e+00 -1.44904804e+00\n",
            "  -7.97170043e-01 -1.28034973e+00 -1.49200583e+00 -1.09599245e+00]\n",
            " [-1.06845748e+00 -1.26151061e+00  5.08459508e-02  4.62956727e-02\n",
            "  -1.53092444e+00  9.51772451e-01 -9.73227799e-01 -1.04190975e-01\n",
            "  -1.33921361e+00 -1.41178906e-01 -8.65647346e-02 -6.02452397e-01\n",
            "  -1.26418042e+00 -7.08318174e-01 -3.18355590e-01  1.25124383e+00]\n",
            " [-1.15237844e+00 -1.00146449e+00  2.28501141e-01 -5.87303340e-02\n",
            "  -9.66902971e-01  2.52306759e-02 -1.40786493e+00 -2.03900129e-01\n",
            "  -1.40606713e+00 -2.40221113e-01 -9.56291020e-01 -1.26239562e+00\n",
            "  -1.25812614e+00 -1.24127734e+00 -1.24254286e+00  1.06790423e-01]\n",
            " [-1.10162044e+00 -1.06947529e+00  1.88471466e-01  1.86010063e-01\n",
            "  -1.62339306e+00  1.00192499e+00 -9.47730243e-01  7.01573491e-03\n",
            "  -2.58153605e+00  2.28157908e-01 -2.02084869e-01 -5.72614372e-01\n",
            "  -1.36743617e+00 -1.00094020e+00  1.48386553e-01  1.23175955e+00]\n",
            " [-2.75352299e-02 -9.24367964e-01 -7.14508891e-02  2.36365020e-01\n",
            "  -1.21136260e+00 -5.37574589e-02 -1.03008902e+00  1.64582610e-01\n",
            "  -1.02151835e+00  1.20043486e-01  1.47511065e-01 -9.54623461e-01\n",
            "  -1.06841052e+00 -1.14676487e+00 -1.61988020e-01 -1.07936174e-01]\n",
            " [-2.62025595e-02  1.60472795e-01 -1.54631466e-01  7.79533386e-02\n",
            "   7.35772820e-03  9.83349383e-01 -6.08694196e-01  7.54590034e-02\n",
            "  -1.33986795e+00  2.25433439e-01 -3.81676108e-01 -4.99349892e-01\n",
            "  -9.39755678e-01 -6.75758958e-01 -2.07367003e-01  1.13366330e+00]\n",
            " [-2.20339924e-01  8.67063999e-02  2.20712245e-01  1.24574125e-01\n",
            "  -2.20743388e-01  1.79585129e-01 -9.92233753e-02 -5.95489740e-02\n",
            "  -2.08487487e+00  2.44717717e-01 -2.01606417e+00 -1.31355226e-01\n",
            "  -2.37799466e-01 -1.49139136e-01 -2.07733274e-01  1.66546613e-01]]\n",
            "layer_2.bias \n",
            " [-1.3882447  -0.22272635 -1.1662401  -0.87559825 -0.9843379  -0.12586443\n",
            " -1.6095773  -0.5322513  -1.2492031  -1.3184148  -0.64853746 -1.4056855\n",
            "  0.32151082 -1.3468456  -0.00815943 -2.2689266 ]\n",
            "layer_out.weight \n",
            " [[ 6.4655924e-01 -1.6284972e-02 -1.0135028e+00 -4.6980524e-01\n",
            "  -9.1439337e-01  8.9223158e-01  5.3892933e-02 -2.8034886e-02\n",
            "   9.9721479e-01  6.0496058e-02 -2.5094396e-01  1.0127761e+00\n",
            "  -2.7505544e-01  1.0606143e+00 -1.0454954e-03  2.0039015e+00]]\n",
            "layer_out.bias \n",
            " [-3.2878797]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([[-7.6361716e-01, -9.6137363e-01, -1.2890092e+00],\n",
        "              [-1.6484374e+00, -1.2446281e+00, -2.8065202e-01],\n",
        "              [-3.7659967e-01, -1.7605126e-01, -4.0795925e-01],\n",
        "              [-3.5579336e-01,  3.8047922e-01,  5.2891925e-02],\n",
        "              [ 2.4721961e+00, -2.7543845e+00,  8.4818310e-01],\n",
        "              [-9.3265837e-01, -8.5103296e-02, -5.3403342e-01],\n",
        "              [-6.4755523e-01, -8.7892908e-01, -1.1558753e+00],\n",
        "              [-2.0547803e-01,  1.9645396e-01, -2.6580483e-01],\n",
        "              [ 8.8290489e-01,  2.7862976e+00,  2.4327371e+00],\n",
        "              [-3.8864744e-01, -1.9766942e-01,  3.0926931e-01],\n",
        "              [-1.3255872e-01, -2.3699251e-03, -1.5114504e+00],\n",
        "              [-7.0394403e-01, -7.9321200e-01, -1.1416259e+00],\n",
        "              [ 1.8806453e+00,  4.1271353e-01,  2.3110182e+00],\n",
        "              [ 2.6527099e-02, -7.9279184e-01,  3.1459928e-01],\n",
        "              [-9.1387916e-01, -9.9957138e-01, -1.2331336e+00],\n",
        "              [-1.1269437e+00, -2.3560557e-01, -3.3136231e-01]])\n",
        "\n",
        "np.sum(np.abs(a), axis=0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqaZn2s6Eoq4",
        "outputId": "b8d507dc-0cb1-456b-c8c0-5f522d1725f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13.45838566, 12.89763431, 14.41960515])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6jWUNnBjEwNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}